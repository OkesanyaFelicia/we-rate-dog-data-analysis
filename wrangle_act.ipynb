{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE RATE DOG DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TABLE OF CONTENT\n",
    "1.[Introduction](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Introduction)\n",
    "\n",
    "2.[Gathering Data](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Data-Gathering)\n",
    "\n",
    "3.[Assessing Data](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Assessing-Data)\n",
    "\n",
    "4.[Cleaning Data](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Cleaning-Data)\n",
    "\n",
    "5.[Storing Data](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Storing-Data)\n",
    "\n",
    "6.[Analysing and Visualizing Data](https://viewf6b31853.udacity-student-workspaces.com/notebooks/wrangle_act.ipynb#Analyzing-and-Visualizing-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goal\n",
    "\n",
    "My goal is to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. The Twitter archive is great, but it only contains very basic tweet information. Additional gathering, then assessing and cleaning is required for \"Wow!\"-worthy analyses and visualizations.\n",
    "\n",
    "#### The Data\n",
    "In this project, i will work on the following three datasets.\n",
    "\n",
    "#### Enhanced Twitter Archive\n",
    "\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which was used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets,tweets with ratings only  are been filtered (there are 2356).\n",
    "\n",
    "The extracted data from each tweet's text was extrated  programmatically, but it was not extracted properly . The ratings probably aren't all correct. Same goes for the dog names and probably dog stages (see below for more information on these) too. I'll need to assess and clean these columns if you want to use them for analysis and visualization.\n",
    "\n",
    "#### Additional Data via the Twitter API\n",
    "\n",
    "Back to the basic-ness of Twitter archives: retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API. Well, \"anyone\" who has access to data for the 3000 most recent tweets, at least. But you, because you have the WeRateDogs Twitter archive and specifically the tweet IDs within it, can gather this data for all 5000+. And guess what? You're going to query Twitter's API to gather this valuable data.\n",
    "\n",
    "#### Image Predictions File\n",
    "\n",
    " Ran every image in the WeRateDogs Twitter archive through a neural network that can classify breeds of dogs*. The results: a table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "\n",
    "Image predictions\n",
    "\n",
    "tweet_id is the last part of the tweet URL after \"status/\" → https://twitter.com/dog_rates/status/889531135344209921\n",
    "\n",
    "p1 is the algorithm's #1 prediction for the image in the tweet → golden retriever\n",
    "\n",
    "p1_conf is how confident the algorithm is in its #1 prediction → 95%\n",
    "\n",
    "p1_dog is whether or not the #1 prediction is a breed of dog → TRUE\n",
    "\n",
    "p2 is the algorithm's second most likely prediction → Labrador retriever\n",
    "\n",
    "p2_conf is how confident the algorithm is in its #2 prediction → 1%\n",
    "\n",
    "p2_dog is whether or not the #2 prediction is a breed of dog → TRUE\n",
    "etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all libraries needed for analysis\n",
    "import pandas as pd \n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn==0.11.0 in /opt/conda/lib/python3.6/site-packages (0.11.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /opt/conda/lib/python3.6/site-packages (from seaborn==0.11.0) (0.23.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /opt/conda/lib/python3.6/site-packages (from seaborn==0.11.0) (3.3.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.6/site-packages (from seaborn==0.11.0) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.6/site-packages (from seaborn==0.11.0) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23->seaborn==0.11.0) (2.6.1)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas>=0.23->seaborn==0.11.0) (2017.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from matplotlib>=2.2->seaborn==0.11.0) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn==0.11.0) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn==0.11.0) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn==0.11.0) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.23->seaborn==0.11.0) (1.11.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upgrade seaborn and import seaborn libarary\n",
    "!pip install seaborn==0.11.0\n",
    "import seaborn as sns\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#programmatically importing the twitter_archive_enhanced csv file\n",
    "dogs_rating = pd.read_csv('twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#using the requests library to download the tweet image prediction tsv file\n",
    "url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'\n",
    "response=requests.get(url)\n",
    "with open ('image-predictions.tsv','wb')as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response.content to a dataframe\n",
    "image_prediction=pd.read_csv('image-predictions.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query additional data via the Twitter API (tweet_json.txt)\n",
    "tweet=pd.read_json('tweet-json.txt',lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Assessing Data\n",
    "I only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesssing  dogs_rating data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892420643555336193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 16:23:56 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Phineas. He's a mystical boy. Only eve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892420643...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Phineas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892177421306343426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-01 00:17:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Tilly. She's just checking pup on you....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/892177421...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Tilly</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891815181378084864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-31 00:18:03 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Archie. He is a rare Norwegian Pouncin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891815181...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Archie</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>891689557279858688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-30 15:58:51 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Darla. She commenced a snooze mid meal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891689557...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Darla</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891327558926688256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-07-29 16:00:24 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Franklin. He would like you to stop ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/891327558...</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>Franklin</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "0  892420643555336193                    NaN                  NaN   \n",
       "1  892177421306343426                    NaN                  NaN   \n",
       "2  891815181378084864                    NaN                  NaN   \n",
       "3  891689557279858688                    NaN                  NaN   \n",
       "4  891327558926688256                    NaN                  NaN   \n",
       "\n",
       "                   timestamp  \\\n",
       "0  2017-08-01 16:23:56 +0000   \n",
       "1  2017-08-01 00:17:27 +0000   \n",
       "2  2017-07-31 00:18:03 +0000   \n",
       "3  2017-07-30 15:58:51 +0000   \n",
       "4  2017-07-29 16:00:24 +0000   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "4  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                text  retweeted_status_id  \\\n",
       "0  This is Phineas. He's a mystical boy. Only eve...                  NaN   \n",
       "1  This is Tilly. She's just checking pup on you....                  NaN   \n",
       "2  This is Archie. He is a rare Norwegian Pouncin...                  NaN   \n",
       "3  This is Darla. She commenced a snooze mid meal...                  NaN   \n",
       "4  This is Franklin. He would like you to stop ca...                  NaN   \n",
       "\n",
       "   retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       NaN                        NaN   \n",
       "3                       NaN                        NaN   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "                                       expanded_urls  rating_numerator  \\\n",
       "0  https://twitter.com/dog_rates/status/892420643...                13   \n",
       "1  https://twitter.com/dog_rates/status/892177421...                13   \n",
       "2  https://twitter.com/dog_rates/status/891815181...                12   \n",
       "3  https://twitter.com/dog_rates/status/891689557...                13   \n",
       "4  https://twitter.com/dog_rates/status/891327558...                12   \n",
       "\n",
       "   rating_denominator      name doggo floofer pupper puppo  \n",
       "0                  10   Phineas  None    None   None  None  \n",
       "1                  10     Tilly  None    None   None  None  \n",
       "2                  10    Archie  None    None   None  None  \n",
       "3                  10     Darla  None    None   None  None  \n",
       "4                  10  Franklin  None    None   None  None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the top five rows of the dataframe\n",
    "dogs_rating.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2356 entries, 0 to 2355\n",
      "Data columns (total 17 columns):\n",
      "tweet_id                      2356 non-null int64\n",
      "in_reply_to_status_id         78 non-null float64\n",
      "in_reply_to_user_id           78 non-null float64\n",
      "timestamp                     2356 non-null object\n",
      "source                        2356 non-null object\n",
      "text                          2356 non-null object\n",
      "retweeted_status_id           181 non-null float64\n",
      "retweeted_status_user_id      181 non-null float64\n",
      "retweeted_status_timestamp    181 non-null object\n",
      "expanded_urls                 2297 non-null object\n",
      "rating_numerator              2356 non-null int64\n",
      "rating_denominator            2356 non-null int64\n",
      "name                          2356 non-null object\n",
      "doggo                         2356 non-null object\n",
      "floofer                       2356 non-null object\n",
      "pupper                        2356 non-null object\n",
      "puppo                         2356 non-null object\n",
      "dtypes: float64(4), int64(3), object(10)\n",
      "memory usage: 313.0+ KB\n"
     ]
    }
   ],
   "source": [
    "#information about all columnns in the dataframe\n",
    "dogs_rating.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total rows and columns \n",
    "dogs_rating.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicated rows\n",
    "dogs_rating.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12      558\n",
       "11      464\n",
       "10      461\n",
       "13      351\n",
       "9       158\n",
       "8       102\n",
       "7        55\n",
       "14       54\n",
       "5        37\n",
       "6        32\n",
       "3        19\n",
       "4        17\n",
       "1         9\n",
       "2         9\n",
       "420       2\n",
       "0         2\n",
       "15        2\n",
       "75        2\n",
       "80        1\n",
       "20        1\n",
       "24        1\n",
       "26        1\n",
       "44        1\n",
       "50        1\n",
       "60        1\n",
       "165       1\n",
       "84        1\n",
       "88        1\n",
       "144       1\n",
       "182       1\n",
       "143       1\n",
       "666       1\n",
       "960       1\n",
       "1776      1\n",
       "17        1\n",
       "27        1\n",
       "45        1\n",
       "99        1\n",
       "121       1\n",
       "204       1\n",
       "Name: rating_numerator, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each unique rating numerators and their value counts\n",
    "dogs_rating['rating_numerator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/668625577880875008/photo/1</td>\n",
       "      <td>This is Maks. Maks just noticed something wasn't right. 10/10 https://t.co/0zBycaxyvs</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Maks</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweeted_status_user_id  in_reply_to_user_id  \\\n",
       "2208 NaN                       NaN                    \n",
       "\n",
       "                                                        expanded_urls  \\\n",
       "2208  https://twitter.com/dog_rates/status/668625577880875008/photo/1   \n",
       "\n",
       "                                                                                       text  \\\n",
       "2208  This is Maks. Maks just noticed something wasn't right. 10/10 https://t.co/0zBycaxyvs   \n",
       "\n",
       "      rating_numerator  rating_denominator  name doggo floofer pupper puppo  \n",
       "2208  10                10                  Maks  None  None    None   None  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the ellipses \n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "# checking if ellipses had been removed\n",
    "dogs_rating[dogs_rating['tweet_id']==668625577880875008][['retweeted_status_user_id','in_reply_to_user_id','expanded_urls','text','rating_numerator','rating_denominator','name','doggo','floofer','pupper','puppo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     2333\n",
       "11     3   \n",
       "50     3   \n",
       "80     2   \n",
       "20     2   \n",
       "2      1   \n",
       "16     1   \n",
       "40     1   \n",
       "70     1   \n",
       "15     1   \n",
       "90     1   \n",
       "110    1   \n",
       "120    1   \n",
       "130    1   \n",
       "150    1   \n",
       "170    1   \n",
       "7      1   \n",
       "0      1   \n",
       "Name: rating_denominator, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each unique rating denominators and their value counts\n",
    "dogs_rating['rating_denominator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>text</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>835246439529840640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26259576.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jonnysun @Lin_Manuel ok jomny I know you're excited but 960/00 isn't a valid rating, 13/10 is tho</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweet_id  retweeted_status_user_id  in_reply_to_user_id  \\\n",
       "313  835246439529840640 NaN                        26259576.0            \n",
       "\n",
       "    expanded_urls  \\\n",
       "313  NaN            \n",
       "\n",
       "                                                                                                   text  \\\n",
       "313  @jonnysun @Lin_Manuel ok jomny I know you're excited but 960/00 isn't a valid rating, 13/10 is tho   \n",
       "\n",
       "     rating_numerator  rating_denominator  name doggo floofer pupper puppo  \n",
       "313  960               0                   None  None  None    None   None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the row with rating_denominator of '0'\n",
    "dogs_rating[dogs_rating['rating_denominator']==0][['tweet_id','retweeted_status_user_id','in_reply_to_user_id','expanded_urls','text','rating_numerator','rating_denominator','name','doggo','floofer','pupper','puppo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp',\n",
       "       'source', 'text', 'retweeted_status_id', 'retweeted_status_user_id',\n",
       "       'retweeted_status_timestamp', 'expanded_urls', 'rating_numerator',\n",
       "       'rating_denominator', 'name', 'doggo', 'floofer', 'pupper', 'puppo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking if all column headers are in small letter and seperated by undescore\n",
    "dogs_rating.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                      int64  \n",
       "in_reply_to_status_id         float64\n",
       "in_reply_to_user_id           float64\n",
       "timestamp                     object \n",
       "source                        object \n",
       "text                          object \n",
       "retweeted_status_id           float64\n",
       "retweeted_status_user_id      float64\n",
       "retweeted_status_timestamp    object \n",
       "expanded_urls                 object \n",
       "rating_numerator              int64  \n",
       "rating_denominator            int64  \n",
       "name                          object \n",
       "doggo                         object \n",
       "floofer                       object \n",
       "pupper                        object \n",
       "puppo                         object \n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#datatype for each column\n",
    "dogs_rating.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.356000e+03</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>1.810000e+02</td>\n",
       "      <td>2356.000000</td>\n",
       "      <td>2356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.427716e+17</td>\n",
       "      <td>7.455079e+17</td>\n",
       "      <td>2.014171e+16</td>\n",
       "      <td>7.720400e+17</td>\n",
       "      <td>1.241698e+16</td>\n",
       "      <td>13.126486</td>\n",
       "      <td>10.455433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.856705e+16</td>\n",
       "      <td>7.582492e+16</td>\n",
       "      <td>1.252797e+17</td>\n",
       "      <td>6.236928e+16</td>\n",
       "      <td>9.599254e+16</td>\n",
       "      <td>45.876648</td>\n",
       "      <td>6.745237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.660209e+17</td>\n",
       "      <td>6.658147e+17</td>\n",
       "      <td>1.185634e+07</td>\n",
       "      <td>6.661041e+17</td>\n",
       "      <td>7.832140e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.783989e+17</td>\n",
       "      <td>6.757419e+17</td>\n",
       "      <td>3.086374e+08</td>\n",
       "      <td>7.186315e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.196279e+17</td>\n",
       "      <td>7.038708e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>7.804657e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.993373e+17</td>\n",
       "      <td>8.257804e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>8.203146e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.924206e+17</td>\n",
       "      <td>8.862664e+17</td>\n",
       "      <td>8.405479e+17</td>\n",
       "      <td>8.874740e+17</td>\n",
       "      <td>7.874618e+17</td>\n",
       "      <td>1776.000000</td>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "count  2.356000e+03  7.800000e+01           7.800000e+01          \n",
       "mean   7.427716e+17  7.455079e+17           2.014171e+16          \n",
       "std    6.856705e+16  7.582492e+16           1.252797e+17          \n",
       "min    6.660209e+17  6.658147e+17           1.185634e+07          \n",
       "25%    6.783989e+17  6.757419e+17           3.086374e+08          \n",
       "50%    7.196279e+17  7.038708e+17           4.196984e+09          \n",
       "75%    7.993373e+17  8.257804e+17           4.196984e+09          \n",
       "max    8.924206e+17  8.862664e+17           8.405479e+17          \n",
       "\n",
       "       retweeted_status_id  retweeted_status_user_id  rating_numerator  \\\n",
       "count  1.810000e+02         1.810000e+02              2356.000000        \n",
       "mean   7.720400e+17         1.241698e+16              13.126486          \n",
       "std    6.236928e+16         9.599254e+16              45.876648          \n",
       "min    6.661041e+17         7.832140e+05              0.000000           \n",
       "25%    7.186315e+17         4.196984e+09              10.000000          \n",
       "50%    7.804657e+17         4.196984e+09              11.000000          \n",
       "75%    8.203146e+17         4.196984e+09              12.000000          \n",
       "max    8.874740e+17         7.874618e+17              1776.000000        \n",
       "\n",
       "       rating_denominator  \n",
       "count  2356.000000         \n",
       "mean   10.455433           \n",
       "std    6.745237            \n",
       "min    0.000000            \n",
       "25%    10.000000           \n",
       "50%    10.000000           \n",
       "75%    10.000000           \n",
       "max    170.000000          "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#statistical summary of all quantitative column\n",
    "dogs_rating.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking expanded_urls   for null values\n",
    "dogs_rating[dogs_rating['expanded_urls'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if all tweet id are unique\n",
    "dogs_rating['tweet_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acessing image_prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#30 random rows of the dataframe\n",
    "image_prediction.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique values in img_num column\n",
    "image_prediction['img_num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total rows and column \n",
    "image_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datatype for all columns\n",
    "image_prediction.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicated rows\n",
    "image_prediction.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if all values in tweet_id are unique,because there shouldn't be any duplicated tweet_id\n",
    "image_prediction.tweet_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#information about all columns in the dataframe\n",
    "image_prediction.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 random rows of the dataframe\n",
    "tweet.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total rows and column\n",
    "tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#information about all columns in the dataframe\n",
    "tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#datatype for all columns\n",
    "tweet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.favorited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure no duplicated tweet_id\n",
    "tweet.id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking whether it is tweet_id or tweet_id_str that matches other dataset tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 ramdom sample of tewwt_id column\n",
    "tweet.id.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rows where tweet.id_str is not equal to tweet.id\n",
    "tweet[tweet.id_str!=tweet.id][['id','id_str']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching for a particular tweet_id_str in dogs_rating which could not be found\n",
    "dogs_rating.loc[dogs_rating['tweet_id']==693590843962331136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#searching for a particular tweet_id in dogs_rating, which  could be found\n",
    "dogs_rating.loc[dogs_rating['tweet_id']==693590843962331137]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking the is_quote_status column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.is_quote_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.loc[tweet.is_quote_status==True][['id']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating.loc[dogs_rating['tweet_id']==804475857670639616]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction.loc[image_prediction['tweet_id']==804475857670639616]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking lang column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.lang.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking place column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.place.unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking retweeted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet['retweeted'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all columns in the dataframe\n",
    "tweet.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality issues\n",
    "\n",
    "1.tweet_id,rating_numerator,rating_denominator wrong datatype\n",
    "\n",
    "2.timestamp wrong datatype\n",
    "\n",
    "3.name column values to lowercase\n",
    "\n",
    "4.Ambiguous column header\n",
    "\n",
    "5.Erroneous column datatype\n",
    "\n",
    "6.Some of the image predictions are not dog\n",
    "\n",
    "7.columns in image_prediction dataset that will not be need for futher analysis\n",
    "\n",
    "8.Inconsistent column header for all dataset\n",
    "\n",
    "9.Some of the ratings are not dog_ratings\n",
    "\n",
    "10.Some of the dog_ratings doesnt have likes _counts\n",
    "\n",
    "11.Some of the dog_ratings are retweets\n",
    "\n",
    "12.Incorrect names\n",
    "\n",
    "13.Plagarism rating included in the dataset\n",
    "\n",
    "14.Tweet_id '810984652412424192' is not dog rating \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Tidiness issues\n",
    "\n",
    "1.dog stage in  different column\n",
    "2.All the three dataset should be merged together "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Cleaning Data\n",
    "In this section,  **all** issues documented while assessing are been cleaned  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make copies of the three original dataframe\n",
    "dogs_rating_clean=dogs_rating.copy()\n",
    "image_prediction_clean=image_prediction.copy()\n",
    "tweet_clean=tweet.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dogs_rating cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1:  tweet_id,rating_numerator,rating_denominator wrong datatype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Since no calcualation will be done with tweet_id,rating_numerator,rating_denominator use d astype funtion to convert to string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean[['rating_numerator','rating_denominator','tweet_id']] = dogs_rating_clean[['rating_numerator','rating_denominator','tweet_id']].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean[['rating_numerator','rating_denominator','tweet_id']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2: timestamp wrong datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "source": [
    "#### Define \n",
    "Use pd to datetime to convert the timestamp column to datetype datatype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean['timestamp']= pd.to_datetime(dogs_rating_clean['timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_rating_clean['timestamp'].sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:name column values  to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Change all names to small letter for easy slicing,merging and manupulation using the lower function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean['name']=dogs_rating_clean.name.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#shows that in all 2356 rows all values in name column are all  in lowercase \n",
    "dogs_rating_clean['name'].str.islower().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #4: dogs types in  different column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "use the melt function that changes the format structure of my dataframe from a wide format to a long format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the unique value in each dog stage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.doggo.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.floofer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.pupper.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.pupper.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all rows that has all it dog stage as 'none',the use the melt function to melt all dog_stage together ,then drop duplicated rows and the column not needed\n",
    "no_dog_stage=dogs_rating_clean[(dogs_rating_clean.doggo=='None')\n",
    "                               &(dogs_rating_clean.floofer=='None')\n",
    "                               &(dogs_rating_clean.pupper=='None')\n",
    "                               &(dogs_rating_clean.puppo=='None')]\n",
    "no_dog_stage=pd.melt(no_dog_stage,id_vars=['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp','source', 'text', 'retweeted_status_id', 'retweeted_status_user_id','retweeted_status_timestamp', 'expanded_urls', 'rating_numerator','rating_denominator', 'name'],var_name='dog_stage_',value_name='dog_stage')\n",
    "no_dog_stage=no_dog_stage.drop(['dog_stage_'],axis=1)\n",
    "no_dog_stage=no_dog_stage.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt all dog stage of the original dataset and filter out rows that has 'None' dog stage and drop column not needed \n",
    "dogs_rating_clean=pd.melt(dogs_rating_clean,id_vars=['tweet_id', 'in_reply_to_status_id', 'in_reply_to_user_id', 'timestamp','source', 'text', 'retweeted_status_id', 'retweeted_status_user_id','retweeted_status_timestamp', 'expanded_urls', 'rating_numerator','rating_denominator', 'name'],var_name='dog_stage_',value_name='dog_stage')\n",
    "dogs_rating_clean=dogs_rating_clean[dogs_rating_clean['dog_stage']!='None']\n",
    "dogs_rating_clean=dogs_rating_clean.drop(['dog_stage_'],axis=1)\n",
    "#add the no_dog_stage to the dataframe and drop rows with two different type of dog stage while keeping the first row detected  \n",
    "dogs_rating_clean=dogs_rating_clean.append(no_dog_stage,ignore_index=True)\n",
    "dogs_rating_clean=dogs_rating_clean.drop_duplicates(subset=['tweet_id'],keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#unique values in dog stage column and their respective counts \n",
    "dogs_rating_clean.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicated tweet_id\n",
    "dogs_rating_clean.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if all columns not needed have been successfully dropped \n",
    "list(dogs_rating_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confirming total rows and columns\n",
    "dogs_rating_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image_prediction cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:Ambiguous column header "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Change the column name to a more readable name using the rename function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.rename(columns={'p1':'predicion_1',\n",
    "                                 'p1_conf':'prediction_1_conf',\n",
    "                                 'p1_dog':'prediction_1_dog',\n",
    "                                 'p2':'prediction_2',\n",
    "                                 'p2_conf':'prediction_2_conf',\n",
    "                                 'p2_dog':'prediction_2_dog',\n",
    "                                 'p3':'prediction_3',\n",
    "                                 'p3_conf':'prediction_3_conf',\n",
    "                                 'p3_dog':'prediction_3_dog'},\n",
    "                             inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list(image_prediction_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:Erroneous column datatype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Since no calcualation will be done with tweet_id use d astype funtion to convert to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean['tweet_id']=image_prediction_clean['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.tweet_id.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:Some of the image predictions are not dog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define drop all image prediction that couldn't at least recognise one dog in its three predicction i.e at least 1 true recognition of dog in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images that are recognised false in the three prediction \n",
    "Non_dogs=image_prediction_clean[(image_prediction_clean['prediction_1_dog']==False)\n",
    "                &(image_prediction_clean['prediction_2_dog']==False)\n",
    "                &(image_prediction_clean['prediction_3_dog']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of prediction with three  false prediction \n",
    "len(Non_dogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the non_dog dataset to confirm thay are all false in the three prediction \n",
    "Non_dogs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the non dog datset with the image prediction dataset \n",
    "image_prediction_clean=pd.merge(image_prediction_clean,Non_dogs,how='outer',indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the merge column to ensure they where properly merge\n",
    "image_prediction_clean._merge.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows that has false value in the three prediction \n",
    "image_prediction_clean['_merge']=image_prediction_clean['_merge'].loc[image_prediction_clean['_merge']!='both']\n",
    "image_prediction_clean=image_prediction_clean.dropna(subset=['_merge'],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the _merge column \n",
    "image_prediction_clean.drop('_merge',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking if the _merge column still exist \n",
    "list(image_prediction_clean)=='_merge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if rows with its three prediction as false are no longer in the dataset\n",
    "len(image_prediction_clean[(image_prediction_clean['prediction_1_dog']==False)\n",
    "                &(image_prediction_clean['prediction_2_dog']==False)\n",
    "                &(image_prediction_clean['prediction_3_dog']==False)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: columns in image_prediction dataset that will not be need for futher analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define: Use the drop function to drop for following columns:img_num', 'predicion_1', 'prediction_1_conf','prediction_1_dog', 'prediction_2', 'prediction_2_conf','prediction_2_dog', 'prediction_3', 'prediction_3_conf','prediction_3_dog'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean=image_prediction_clean.drop(['img_num', 'predicion_1', 'prediction_1_conf','jpg_url','prediction_1_dog', 'prediction_2', 'prediction_2_conf','prediction_2_dog', 'prediction_3', 'prediction_3_conf','prediction_3_dog'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_prediction_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:columns not needed for futher analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Use the drop function to drop the folowing columns : contributor,cordinator and geo column as they are all null value\n",
    "display_text_range,id_str as it doesnt correspond with other dataset\n",
    "drop in_reply_to_status_id', 'in_reply_to_status_id_str',in_reply_to_user_id',  'in_reply_to_user_id_str',quoted_status','quoted_status_id_str','possibly_sensitive', possibly_sensitive_appealable.user.source,truncated,quoted_status_id_str,place\n",
    "lang column,i dont undertand the concept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_clean=tweet_clean[['created_at', 'favorite_count', 'id','retweet_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:Inconsistent column header for all dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "use the rename function to change the column header 'created at' to the column name that matches other dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_clean=tweet_clean.rename(columns={'created_at':'timestamp',\n",
    "                                       'id':'tweet_id',\n",
    "                                        'favorite_count':'likes_count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tweet_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:Erroneous datatype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Since no calcualation will be done with tweet_id use d astype funtion to convert to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_clean=tweet_clean.rename(columns={'created_at':'timestamp',\n",
    "                                       'id':'tweet_id',\n",
    "                                        'favorite_count':'likes_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_clean['tweet_id']=tweet_clean['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_clean.tweet_id.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Some of the ratings are not dog_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Some ratings in the dogs_rating dataset are not dog ratings ,use the image_prediction that helps detect if the rating is for dog to filter all ratings of dog with at least 1 true recognition of dog in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_rating_clean=pd.merge(dogs_rating_clean,image_prediction_clean,on='tweet_id',how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Some of the dog_ratings doesnt have likes _counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "i only want original ratings (no retweets) that have images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean=pd.merge(dogs_rating_clean,tweet_clean,on=['tweet_id','timestamp'],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dogs_rating_clean.replace('None',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Some of the dog_ratings are retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "i only want original ratings (no retweets) that have images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean=dogs_rating_clean[dogs_rating_clean.retweeted_status_id.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_rating_clean.retweeted_status_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3:columns not needed for futher analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "Use the drop function to drop the folowing columns:'in_reply_to_status_id','in_reply_to_user_id','source','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean=dogs_rating_clean.drop(['in_reply_to_status_id','in_reply_to_user_id','source','retweeted_status_id','retweeted_status_user_id','retweeted_status_timestamp'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dogs_rating_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Incorrect names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define:\n",
    "manully detect all incorrect nameand use the replace function to replace them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.name.replace('none',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_name=['the','all','my','space','a','an','not','very','just']\n",
    "dogs_rating_clean.name[dogs_rating_clean.name.isin(incorrect_name)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in incorrect_name:\n",
    "    if name == 'my':\n",
    "        dogs_rating_clean['name'].replace(name,'zoey',inplace=True)\n",
    "    elif name== 'space':\n",
    "         dogs_rating_clean['name'].replace(name,'space pup',inplace=True)\n",
    "    else:\n",
    "         dogs_rating_clean['name'].replace(name,np.nan,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.name[dogs_rating_clean.name.isin(incorrect_name)].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: wrongly extracted decimal rating_numerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define\n",
    "Extract all decimal rating from the text column using a regrex pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract all decimal rating from the text column using a regrex pattern\n",
    "dogs_rating_clean['extract']= dogs_rating_clean['text'].str.extract(pat='([0-9]+\\.[0-9]+/[0-9]+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splict the extracted rating into numerator and denominator ,then drop the extracted column and the denominator column \n",
    "dogs_rating_clean['numerator_'],dogs_rating_clean['denominator']=dogs_rating_clean['extract'].str.split('/',1).str\n",
    "dogs_rating_clean=dogs_rating_clean.drop(['extract','denominator'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting all decimal numerator\n",
    "dogs_rating_clean['numerator_'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all wrong rating numerator \n",
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='778027034220126208','rating_numerator']='11.27'\n",
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='883482846933004288','rating_numerator']='13.5'\n",
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='786709082849828864','rating_numerator']='9.75'\n",
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='680494726643068929','rating_numerator']='11.26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the numerator_ column created \n",
    "dogs_rating_clean.drop(['numerator_'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decimal_numerator=['11.27', '13.5', '9.75', '11.26']\n",
    "dogs_rating_clean[dogs_rating_clean['rating_numerator'].isin(decimal_numerator)]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3: Tweet_id '810984652412424192' is not dog rating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Tweet_id '810984652412424192' uses 24/7 as rating ,this is not rating but telling us the dog smiles all the time ,so i will use the drop function to drop this row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping 24/7 rating \n",
    "dogs_rating_clean=dogs_rating_clean.drop([567],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='810984652412424192']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3 Plagarism rating included in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define \n",
    "Tweet_id '835152434251116546' uses 0/10 as rating ,it isnt a dog rating just plagarism rating the real rating has been done in row with dis timestamp'2016-07-11 15:07:30 ',use the drop function to drop the row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dogs_rating_clean=dogs_rating_clean.drop([453],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dogs_rating_clean.loc[dogs_rating_clean['tweet_id']=='835152434251116546']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Save gathered, assessed, and cleaned master dataset to a CSV file named \"twitter_archive_master.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_rating_clean.to_csv('twitter_archive_master.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing and Visualizing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions for analysis\n",
    "1.The most popular dog names?\n",
    "2.What year was the highest dog rating tweeted?\n",
    "3.What tweet id had the highest likes and what is the rating for the  dog? \n",
    "4.Is there any relationship between likes and retweet?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question 1:The most popular dog names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most popular dog name\n",
    "popular_dog_names=dogs_rating_clean.name.value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(x=popular_dog_names.index,y=popular_dog_names.values,palette=['blue','blue','blue','grey','grey','grey','grey','grey','grey','grey'])\n",
    "plt.title('most_popular_dog_name',fontsize=20)\n",
    "plt.xlabel('dog_name',fontsize=18)\n",
    "plt.ylabel('name_count',fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>the most popular dog names are:Charlie,Cooper,Lucy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question 2:What year was the highest dog rating tweeted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the years and month from the timestamp column \n",
    "dogs_rating_clean['year']=pd.DatetimeIndex(dogs_rating_clean.timestamp).year\n",
    "dogs_rating_clean['month']=pd.DatetimeIndex(dogs_rating_clean.timestamp).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=dogs_rating_clean,x='year')\n",
    "plt.title('Number of yearly tweet',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>In year 2016 the highest number of original dog_ratings where tweeted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question 3:what tweet id had the highest likes and what is the rating for the  dog ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data=dogs_rating_clean.sort_values(by=['likes_count','retweet_count'],ascending=False).head(10)\n",
    "rating_numerator=filtered_data['rating_numerator'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.relplot(data=filtered_data,x='likes_count',y='retweet_count',size= rating_numerator,sizes=(25,300),style='rating_denominator',hue='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>tweet id  '822872901745569793'  with the rating of  '13/10'  has the highest likes ,but it doesnt have the highest retweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Research Question 4: Is there any relationship between likes and retweet ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=dogs_rating_clean,x='likes_count',y='retweet_count',col='year',row='month')\n",
    "plt.title('reweets and likes for each month in a year')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>likes and retweets are positvely related i.e the higher the likes, the higher the retweet & the lower the the likes,the lower the retweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights:\n",
    "1.The most popular dog names are:Charlie,Cooper,Lucy\n",
    "\n",
    "2.In year 2016 the highest number of original dog_ratings where tweeted\n",
    "\n",
    "3.Tweet id '822872901745569793' with the rating of '13/10' has the highest likes ,but it doesnt have the highest retweet.\n",
    "\n",
    "4.Likes and retweets are positvely related i.e the higher the likes, the higher the retweet & the lower the the likes,the lower the retweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations:\n",
    "\n",
    "1.Alot of dogs do not have dog name\n",
    "\n",
    "2.Some images that are dog ,where not recognised as dog in the three predictions of the image prediction csv file \n",
    "\n",
    "3.Over 1000 tweets do not contain dog stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Source:\n",
    "      - https://stackoverflow.com/questions/48122744/how-to-download-all-files-and-folder-hierarchy-from-jupyter-notebook\n",
    "\"\"\"\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "def recursive_files(dir_name='.', ignore=None):\n",
    "    for dir_name,subdirs,files in os.walk(dir_name):\n",
    "        if ignore and os.path.basename(dir_name) in ignore:\n",
    "            continue\n",
    "\n",
    "        for file_name in files:\n",
    "            if ignore and file_name in ignore:\n",
    "                continue\n",
    "\n",
    "            yield os.path.join(dir_name, file_name)\n",
    "\n",
    "def make_tar_file(dir_name='.', target_file_name='workspace_archive.tar', ignore=None):\n",
    "    tar = tarfile.open(target_file_name, 'w')\n",
    "\n",
    "    for file_name in recursive_files(dir_name, ignore):\n",
    "        tar.add(file_name)\n",
    "\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "dir_name = '.'\n",
    "target_file_name = 'workspace_archive.tar'\n",
    "# List of files/directories to ignore\n",
    "ignore = {'.ipynb_checkpoints', '__pycache__', target_file_name}\n",
    "\n",
    "make_tar_file(dir_name, target_file_name, ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
